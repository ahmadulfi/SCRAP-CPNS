{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping SSCASN BKN: From Interactive Elements to Meaningful Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so here’s the deal. I’m using this notebook to scrape data from the SSCASN BKN website. Why? Because I’m trying to figure out which job formations have a higher chance of getting me through the CPNS 2025 selection process. Instead of manually shifting through pages and pages of information, Why not let Python do the boring work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is super personal and I’m basically building my own cheat sheet to make smarter decisions during the application process. Plus, I get to brush up on my web scraping skills while I’m at it. Win-win, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What’s the Plan?\n",
    "\n",
    "The SSCASN website has everything I need, but it’s not exactly user-friendly for data nerds like me. Especially the filter that only allow us to select one-selection per load. Hence, for the python scrape automation challenge is:\n",
    "\n",
    "- Dropdown menus that dynamically load options.\n",
    "- Pagination, because of course, all the good stuff is spread across multiple pages.\n",
    "- Dynamic tables that make scraping a bit tricky.\n",
    "- The job description of each formation is described in different link. How to gather all that data needed??\n",
    "\n",
    "The goal? \n",
    "\n",
    "Automate the whole process so I can get clean data in one go. Then let's analyze the data retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is path to the chromedriver. You can adjust as you need\n",
    "path_chromedriver = os.path.join(os.getcwd(), \"chromedriver-win64\", \"chromedriver.exe\")\n",
    "\n",
    "chrome_options = Options()\n",
    "service = Service(executable_path=path_chromedriver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load the Driver\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "url = \"https://sscasn.bkn.go.id/\" # this is the website links\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function was initially created for development purposes to reset the web driver back to the homepage of the SSCASN website. It was particularly useful for troubleshooting or ensuring the code ran smoothly by restarting the scraping process from a clean state. \n",
    "\n",
    "Now, it is also used as a convenient way to return to the homepage during operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_scrap(): \n",
    "    \"\"\"\n",
    "    This function is created to reset the website into homepage.    \n",
    "    \"\"\"\n",
    "    url = \"https://sscasn.bkn.go.id/\"\n",
    "    driver.get(url)  \n",
    "reset_scrap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I limit the filters into my desired criteria, you may adjust it as you need \n",
    "(make sure the text matches exactly what already on the websites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "jenjang = \"S-1/Sarjana\"\n",
    "pengadaan = \"CPNS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I want to perform multiple searchers, My plan is to loop through the prodi list and retrieve all the data for each prodi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prodi_list = [\n",
    "    \"S-1 ILMU STATISTIK\",\n",
    "    \"S-1 ILMU STATISTIKA\",\n",
    "    \"S-1 KEPENDUDUKAN DAN STATISTIK\",\n",
    "    \"S-1 KOMPUTASI STATISTIKA\",\n",
    "    \"S-1 MATEMATIKA STATISTIKA\",\n",
    "    \"S-1 STATISTIK\",\n",
    "    \"S-1 STATISTIK (DATA ANALISIS)\",\n",
    "    \"S-1 STATISTIK KEUANGAN\",\n",
    "    \"S-1 STATISTIK KOMPUTASI\",\n",
    "    \"S-1 STATISTIKA\",\n",
    "    \"S-1 STATISTIKA BISNIS DAN INDUSTRI\",\n",
    "    \"S-1 STATISTIKA DAN SAINS DATA\",\n",
    "    \"S-1 STATISTIKA TERAPAN\",\n",
    "    \"S-1/D-IV STATISTIK\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's is the data to interact with the filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = [] #initiate base data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interact_with_filter(jenjang,prodi):\n",
    "    global all_data\n",
    "\n",
    "    # Select the \"Jenjang Pendidikan\"\n",
    "    jenjang_pendidikan = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, '//*[@id=\"pencarian\"]/div/div/form/div[1]/div[1]/div/div/div/input'))\n",
    "    )\n",
    "    jenjang_pendidikan.click()\n",
    "\n",
    "    options = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.XPATH, \"//li[contains(text(), 'S-1/Sarjana')]\"))\n",
    "    )\n",
    "\n",
    "    for option in options:\n",
    "        if option.text == jenjang:\n",
    "            option.click() \n",
    "            break\n",
    "    time.sleep(1)  # Give the website time to load\n",
    "\n",
    "    # Select the \"Prodi\"\n",
    "    prodi_path = '//*[@id=\"pencarian\"]/div/div/form/div[1]/div[2]/div/div/div/input'\n",
    "    prodi_select = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, prodi_path))\n",
    "    )\n",
    "    prodi_select.click()\n",
    "\n",
    "    options = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.XPATH, f\"//li[contains(text(),'{prodi}')]\"))\n",
    "    )\n",
    "\n",
    "    for option in options:\n",
    "        if option.text == prodi:\n",
    "            option.click()\n",
    "            break\n",
    "\n",
    "    time.sleep(1)  # Give the website time to load\n",
    "\n",
    "    # Select the \"CPNS\"\n",
    "    pengadaan_path = '//*[@id=\"pencarian\"]/div/div/form/div[1]/div[4]/div/div/div/input'\n",
    "    pengadaan_select = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, pengadaan_path))\n",
    "    )\n",
    "    pengadaan_select.click()\n",
    "\n",
    "    options = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.XPATH, f\"//li[contains(text(),'{pengadaan}')]\"))\n",
    "    )\n",
    "\n",
    "    for option in options:\n",
    "        if option.text == pengadaan:\n",
    "            option.click()\n",
    "\n",
    "    time.sleep(1)  # Again, give the website time to load \n",
    "\n",
    "    # Finally, click the Search button\n",
    "    cari_path = '//*[@id=\"pencarian\"]/div/div/form/div[1]/div[5]/a'\n",
    "    driver.find_element(By.XPATH, cari_path).click()\n",
    "\n",
    "    time.sleep(5)  # Give the website time to load the tables\n",
    "\n",
    "    # Let's check for how many pages there are\n",
    "    total_formasi_path = driver.find_element(By.XPATH, '//*[@id=\"daftarFormasi\"]/div[2]/div/div/div[3]/ul/li[1]')\n",
    "\n",
    "    text_halaman = total_formasi_path.text\n",
    "    total_formasi = text_halaman.split(': ')[1].split()[0]\n",
    "    total_page = math.ceil(int(total_formasi) / 10)\n",
    "    \n",
    "    return total_page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function defines how to interact with the pagination, specifically the '>' button. \n",
    "\n",
    "Why does the code look like this? After analying the html structure, I discovered that the button dynamically changes based on unique patterns. To handle this, first I create a base format and then loop through with criteria to match each logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klik(index):\n",
    "    \"\"\"This function created to click the pagination next button\"\"\"\n",
    "    \n",
    "    button_xpath = f'//*[@id=\"daftarFormasi\"]/div[2]/div/div/div[3]/ul/li[{index}]/button'\n",
    "    button = driver.find_element(By.XPATH,button_xpath)\n",
    "    button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and here it is the main agenda, extracting the data. We will extract the data from dynamic table that changes based on pagination and filters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data():\n",
    "    table_data = []\n",
    "    table = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, \"//table\"))\n",
    "    )\n",
    "\n",
    "    rows = table.find_elements(By.XPATH, \".//tbody/tr\")\n",
    "\n",
    "    for row in rows:\n",
    "\n",
    "        cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        row_data = {\n",
    "            \"Jabatan\": cells[0].text,\n",
    "            \"Instansi\": cells[1].text,\n",
    "            \"Unit Kerja\": cells[2].text,\n",
    "            \"Formasi\": cells[3].text,\n",
    "            \"(PPPK) Khusus disabilitas? (CPNS) Dapat Diisi Disabilitas?\": cells[4].text,\n",
    "            \"Penghasilan (juta)\": cells[5].text,\n",
    "            \"Jumlah Kebutuhan\": cells[6].text,\n",
    "            \"Jumlah Lulus verifikasi\": cells[7].text,\n",
    "            \"Link\": cells[8].find_element(By.TAG_NAME, \"a\").get_attribute('href')\n",
    "        }\n",
    "\n",
    "        table_data.append(row_data)\n",
    "    return table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_data(total_page):\n",
    "    \"\"\"This function is created to loop the extracting progress\"\"\"\n",
    "    global all_data\n",
    "    page_index = 10  \n",
    "    current_page = 1\n",
    "\n",
    "    for i in range(current_page,total_page):\n",
    "        data = extract_data()\n",
    "        all_data.extend(data)\n",
    "\n",
    "        if current_page<=3:\n",
    "            klik(page_index)\n",
    "\n",
    "        elif current_page == total_page-3 or current_page == 4:\n",
    "            page_index = 11\n",
    "            klik(page_index)\n",
    "\n",
    "        elif current_page >= total_page-2:\n",
    "            page_index = 10\n",
    "            klik(page_index)\n",
    "\n",
    "        else:\n",
    "            page_index = 12\n",
    "            klik(page_index)\n",
    "        \n",
    "        current_page += 1\n",
    "    reset_scrap()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prodi in prodi_list:\n",
    "    pages = interact_with_filter(jenjang,prodi)\n",
    "    loop_data(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_data)\n",
    "df.to_excel(\"extracted_data.xlsx\", index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
